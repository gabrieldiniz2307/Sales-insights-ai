"""
Agente de IA para processamento de perguntas sobre vendas
Suporta tanto OpenAI quanto modelos locais gratuitos
"""
import os
import re
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from sqlalchemy.orm import Session
from sqlalchemy import text

# Importa√ß√µes condicionais para diferentes modelos
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

from app import crud
from app.database import get_db

class SalesInsightsAI:
    """
    Agente de IA para an√°lise de vendas com suporte a m√∫ltiplos modelos
    """
    
    def __init__(self):
        self.use_local_model = os.getenv("USE_LOCAL_MODEL", "True").lower() == "true"
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.model_name = os.getenv("MODEL_NAME", "microsoft/DialoGPT-medium")
        self.temperature = float(os.getenv("MODEL_TEMPERATURE", "0.1"))
        self.max_tokens = int(os.getenv("MAX_TOKENS", "500"))
        
        # Inicializa o modelo apropriado
        self.model = None
        self.tokenizer = None
        self._initialize_model()
    
    def _initialize_model(self):
        """Inicializa o modelo de IA apropriado"""
        if not self.use_local_model and OPENAI_AVAILABLE and self.openai_api_key:
            # Configura OpenAI
            openai.api_key = self.openai_api_key
            print("‚úÖ Usando OpenAI GPT")
        elif TRANSFORMERS_AVAILABLE:
            try:
                # Usa modelo local mais leve para demonstra√ß√£o
                print("ü§ñ Inicializando modelo local...")
                self.model = pipeline(
                    "text-generation",
                    model="microsoft/DialoGPT-small",  # Modelo mais leve
                    tokenizer="microsoft/DialoGPT-small",
                    device=-1  # CPU
                )
                print("‚úÖ Modelo local inicializado")
            except Exception as e:
                print(f"‚ùå Erro ao inicializar modelo local: {e}")
                self.model = None
        else:
            print("‚ö†Ô∏è Nenhum modelo de IA dispon√≠vel, usando respostas baseadas em regras")
    
    def _get_database_context(self, db: Session) -> str:
        """Obt√©m contexto do banco de dados para o modelo"""
        try:
            # Busca informa√ß√µes b√°sicas do banco
            summary = crud.get_sales_summary(db)
            top_products = crud.get_top_products_last_month(db, limit=3)
            
            context = f"""
            Contexto do banco de dados de vendas:
            - Total de vendas: {summary['total_sales']}
            - Receita total: R$ {summary['total_revenue']:.2f}
            - Total de produtos: {summary['total_products']}
            - Total de clientes: {summary['total_customers']}
            
            Top 3 produtos mais vendidos no √∫ltimo m√™s:
            """
            
            for i, product in enumerate(top_products, 1):
                context += f"\n{i}. {product['name']} - {product['total_quantity']} unidades - R$ {product['total_revenue']:.2f}"
            
            return context
        except Exception as e:
            return f"Erro ao obter contexto do banco: {str(e)}"
    
    def _execute_sql_query(self, db: Session, query: str) -> List[Dict]:
        """Executa query SQL de forma segura"""
        try:
            # Lista de palavras-chave permitidas para seguran√ßa
            allowed_keywords = ['SELECT', 'FROM', 'WHERE', 'GROUP BY', 'ORDER BY', 'LIMIT', 'JOIN', 'COUNT', 'SUM', 'AVG']
            query_upper = query.upper()
            
            # Verifica se √© uma query SELECT segura
            if not query_upper.strip().startswith('SELECT'):
                return []
            
            # Executa a query
            result = db.execute(text(query))
            columns = result.keys()
            rows = result.fetchall()
            
            # Converte para lista de dicion√°rios
            return [dict(zip(columns, row)) for row in rows]
        except Exception as e:
            print(f"Erro ao executar query: {e}")
            return []
    
    def _analyze_question_intent(self, question: str) -> Dict[str, Any]:
        """Analisa a inten√ß√£o da pergunta"""
        question_lower = question.lower()
        
        intent = {
            'type': 'general',
            'entities': [],
            'time_period': None,
            'metric': None
        }
        
        # Detecta tipo de pergunta
        if any(word in question_lower for word in ['mais vendido', 'top', 'melhor', 'maior']):
            intent['type'] = 'top_products'
        elif any(word in question_lower for word in ['total', 'soma', 'receita', 'faturamento']):
            intent['type'] = 'summary'
        elif any(word in question_lower for word in ['cliente', 'comprador']):
            intent['type'] = 'customer_analysis'
        elif any(word in question_lower for word in ['per√≠odo', 'm√™s', 'semana', 'ano']):
            intent['type'] = 'time_analysis'
        
        # Detecta per√≠odo de tempo
        if '√∫ltima semana' in question_lower or 'semana passada' in question_lower:
            intent['time_period'] = 'last_week'
        elif '√∫ltimo m√™s' in question_lower or 'm√™s passado' in question_lower:
            intent['time_period'] = 'last_month'
        elif 'hoje' in question_lower:
            intent['time_period'] = 'today'
        
        return intent
    
    def _generate_rule_based_response(self, question: str, db: Session) -> str:
        """Gera resposta baseada em regras quando n√£o h√° modelo de IA"""
        intent = self._analyze_question_intent(question)
        
        try:
            if intent['type'] == 'top_products':
                top_products = crud.get_top_products_last_month(db, limit=5)
                if top_products:
                    response = "üèÜ **Produtos mais vendidos no √∫ltimo m√™s:**\n\n"
                    for i, product in enumerate(top_products, 1):
                        response += f"{i}. **{product['name']}** (SKU: {product['sku']})\n"
                        response += f"   ‚Ä¢ Quantidade vendida: {product['total_quantity']} unidades\n"
                        response += f"   ‚Ä¢ Receita: R$ {product['total_revenue']:.2f}\n"
                        response += f"   ‚Ä¢ Pedidos: {product['total_orders']}\n\n"
                    return response
                else:
                    return "N√£o foram encontradas vendas no per√≠odo analisado."
            
            elif intent['type'] == 'summary':
                summary = crud.get_sales_summary(db)
                return f"""üìä **Resumo Geral das Vendas:**

‚Ä¢ **Total de vendas realizadas:** {summary['total_sales']}
‚Ä¢ **Receita total:** R$ {summary['total_revenue']:.2f}
‚Ä¢ **Produtos cadastrados:** {summary['total_products']}
‚Ä¢ **Clientes ativos:** {summary['total_customers']}

üí° *Dados atualizados em tempo real do banco de dados.*"""
            
            else:
                return """ü§ñ **Assistente de Vendas IA**

Posso ajudar voc√™ com an√°lises sobre:
‚Ä¢ Produtos mais vendidos
‚Ä¢ Resumo de vendas e faturamento
‚Ä¢ An√°lise de clientes
‚Ä¢ Relat√≥rios por per√≠odo

**Exemplos de perguntas:**
- "Qual foi o produto mais vendido no √∫ltimo m√™s?"
- "Mostre um resumo das vendas"
- "Qual √© a receita total?"

*Fa√ßa sua pergunta e eu analisarei os dados para voc√™!*"""
        
        except Exception as e:
            return f"‚ùå Erro ao processar sua pergunta: {str(e)}"
    
    def _use_openai_model(self, question: str, context: str) -> str:
        """Usa modelo OpenAI para gerar resposta"""
        try:
            prompt = f"""
            Voc√™ √© um assistente especializado em an√°lise de vendas. 
            Responda √† pergunta do usu√°rio baseado nos dados fornecidos.
            
            Contexto dos dados:
            {context}
            
            Pergunta: {question}
            
            Responda de forma clara, objetiva e profissional em portugu√™s brasileiro.
            Use emojis e formata√ß√£o markdown quando apropriado.
            """
            
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )
            
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"Erro ao usar OpenAI: {str(e)}"
    
    def _use_local_model(self, question: str, context: str) -> str:
        """Usa modelo local para gerar resposta"""
        try:
            if not self.model:
                return self._generate_rule_based_response(question, None)
            
            prompt = f"Pergunta sobre vendas: {question}\nContexto: {context}\nResposta:"
            
            response = self.model(
                prompt,
                max_length=200,
                num_return_sequences=1,
                temperature=self.temperature,
                do_sample=True,
                pad_token_id=50256
            )
            
            generated_text = response[0]['generated_text']
            # Extrai apenas a resposta gerada
            answer = generated_text.split("Resposta:")[-1].strip()
            
            return answer if answer else "Desculpe, n√£o consegui gerar uma resposta adequada."
        except Exception as e:
            return f"Erro no modelo local: {str(e)}"
    
    def process_question(self, question: str, db: Session) -> Dict[str, Any]:
        """
        Processa uma pergunta sobre vendas e retorna insights
        """
        try:
            # Obt√©m contexto do banco de dados
            context = self._get_database_context(db)
            
            # Escolhe o m√©todo de processamento
            if not self.use_local_model and OPENAI_AVAILABLE and self.openai_api_key:
                answer = self._use_openai_model(question, context)
                model_used = "OpenAI GPT-3.5"
            elif self.model:
                answer = self._use_local_model(question, context)
                model_used = "Modelo Local (DialoGPT)"
            else:
                answer = self._generate_rule_based_response(question, db)
                model_used = "Sistema Baseado em Regras"
            
            return {
                'question': question,
                'answer': answer,
                'model_used': model_used,
                'data_source': 'Banco de dados SQLite',
                'timestamp': datetime.now(),
                'context_used': len(context) > 0
            }
        
        except Exception as e:
            return {
                'question': question,
                'answer': f"‚ùå Erro ao processar pergunta: {str(e)}",
                'model_used': "Sistema de Erro",
                'data_source': 'N/A',
                'timestamp': datetime.now(),
                'context_used': False
            }

# Inst√¢ncia global do agente
sales_ai_agent = SalesInsightsAI()

